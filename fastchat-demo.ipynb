{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c92bd3d-4cb4-4d3c-8b61-a35e7680b439",
   "metadata": {},
   "source": [
    "# FastChat Demo\n",
    "This notebook uses the [OpenAI REST API](https://platform.openai.com/docs/api-reference/introduction) to interact with LLMs hosted in a [FastChat](https://github.com/lm-sys/FastChat) deployment.\n",
    "FastChat only supports chat completion and embeddings API endpoints.\n",
    "For use on [jupyterhub.sdsu.edu](jupyterhub.sdsu.edu) select the image \"Stack PRP\". The Stack PRP image and FastChat both use Open AI API v0.28.1.\n",
    "\n",
    "The OpenAI REST API endpoint is availbale at [https://sdsu-rci-fastchat.nrp-nautilus.io/v1](https://sdsu-rci-fastchat.nrp-nautilus.io/v1).\n",
    "\n",
    "Your credentials should be stored in a file `env.yaml`. The API key will be shared with you via your instructor. Your `env.yaml` file should mimic the structure of the provided sample `env-template.yaml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbc422fa-e077-433c-9f05-9a2fe4868eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2b71a0-cc96-4ac1-92b7-c657eb136369",
   "metadata": {},
   "source": [
    "## Import Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77e175a3-b648-4774-8a7b-85eb7ff90cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://sdsu-rci-fastchat.nrp-nautilus.io/v1\n"
     ]
    }
   ],
   "source": [
    "with open('env.yaml', 'r') as f:\n",
    "    env = yaml.safe_load(f)\n",
    "\n",
    "print(env[\"fastchat\"][\"base_url\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cab1a9-14f3-4407-8694-eb12438f9276",
   "metadata": {},
   "source": [
    "## Setup API Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c120c37-7460-4f45-884a-bb6d983b7c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"object\": \"list\",\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"id\": \"vicuna-13b-v1.5-16k\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1707262950,\n",
      "      \"owned_by\": \"fastchat\",\n",
      "      \"root\": \"vicuna-13b-v1.5-16k\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"id\": \"modelperm-kqNnouRJzMd25voUMjzuCw\",\n",
      "          \"object\": \"model_permission\",\n",
      "          \"created\": 1707262950,\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_search_indices\": true,\n",
      "          \"allow_view\": true,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"organization\": \"*\",\n",
      "          \"group\": null,\n",
      "          \"is_blocking\": false\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"vicuna-33b-v1.3\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1707262950,\n",
      "      \"owned_by\": \"fastchat\",\n",
      "      \"root\": \"vicuna-33b-v1.3\",\n",
      "      \"parent\": null,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"id\": \"modelperm-gvDNsDX7SfMPQbdFfyx9BZ\",\n",
      "          \"object\": \"model_permission\",\n",
      "          \"created\": 1707262950,\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_search_indices\": true,\n",
      "          \"allow_view\": true,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"organization\": \"*\",\n",
      "          \"group\": null,\n",
      "          \"is_blocking\": false\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "openai.api_key = env[\"fastchat\"][\"api_key\"]\n",
    "openai.api_base = env[\"fastchat\"][\"base_url\"]\n",
    "\n",
    "# Test config by printing available models\n",
    "models = openai.Model.list()\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9923c114-8548-47d1-8735-792855695ede",
   "metadata": {},
   "source": [
    "## Preprocess paper.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1089429-5caa-47d9-ada0-e25b49a1de5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./paper.txt'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_filename = env['file_name_path']\n",
    "text_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2730a7c3-759f-4ac8-9649-5bf3b07c6e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw transcript character count: 5130\n",
      "Raw transcript word count: 697\n",
      "Raw transcript line count: 7\n"
     ]
    }
   ],
   "source": [
    "transcript_raw = \"\"\n",
    "\n",
    "with open(text_filename, 'r') as f:\n",
    "    transcript_raw = f.read()\n",
    "\n",
    "# Calculate and print info about raw file\n",
    "rawCharCount = len(transcript_raw)\n",
    "rawWordCount = len(transcript_raw.split())\n",
    "rawLineCount = len(transcript_raw.split(\"\\n\"))\n",
    "\n",
    "print(f\"Raw transcript character count: {rawCharCount}\")\n",
    "print(f\"Raw transcript word count: {rawWordCount}\")\n",
    "print(f\"Raw transcript line count: {rawLineCount}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dca5b14d-532e-4cd3-bea2-aee8d64f5092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process transcript as a list to make it iterable\n",
    "transcript_transform = transcript_raw.split(\"\\n\")\n",
    "transcript_concat = \"\".join(transcript_transform)\n",
    "\n",
    "# some models have a word limit in which you can change here, though not limiting this word count might be okay as some tokenizers can handle extra words\n",
    "final_sentence = transcript_concat[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24194b51-8c88-4c52-ae2c-3b411ce524c0",
   "metadata": {},
   "source": [
    "## Ask the LLM to Perform the Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "266411d7-f509-44cb-8b41-2c6f6b86ebd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 3 items discussed in the paper are:\n",
      "\n",
      "1. Attention mechanisms and their limitations: The paper discusses the limitations of the self-attention mechanism in Transformer models, such as the fixed-length context window and the potential difficulties in capturing long-term dependencies in practice.\n",
      "2. The need for a more robust and explainable attention mechanism: The paper aims to address these limitations by introducing the Multi-Head Gaussian Adaptive Attention Mechanism (GAAM), which uses a Gaussian-based modulation of input features to improve the attention mechanism's performance and interpretability.\n",
      "3. The applicability and potential benefits of GAAM: The paper suggests that GAAM can significantly enhance model performance in various domains, such as multimedia recommendation, image classification, and text classification, and offers improved accuracy, robustness, and user experience across diverse and challenging real-world applications.\n"
     ]
    }
   ],
   "source": [
    "# Model can be replaced with the model id from the previous call\n",
    "# \"vicuna-33b-v1.3\" is the second model\n",
    "model = models.data[1].id\n",
    "\n",
    "initial_prompt = \"You will be given the introduction to a scientific paper in Artificial Intelligence. \\\n",
    "From this introduction: Provide the top 3 items discussed and what the researcher is trying to accomplish.\"\n",
    "\n",
    "prompt = final_sentence\n",
    "\n",
    "# create a chat completion\n",
    "completion = openai.ChatCompletion.create(\n",
    "  model=model,\n",
    "  messages=[\n",
    "      {\"role\": \"system\", \"content\": initial_prompt},\n",
    "      {\"role\": \"user\", \"content\": prompt}\n",
    "  ]\n",
    ")\n",
    "\n",
    "# print the completion\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65adb2ff-3eea-4436-b711-a2000d38fae5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
